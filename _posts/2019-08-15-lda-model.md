---
layout: post
title: "Latent-Dirichlet Allocation document categorization         (Python, Natural Langauge Processing)"
date: 2019-08-15
---

Used the Latent-Dirchlet Allocation algorithm in the sklearn Python libray to automatically categorize the top _n_ most popular
news article title subjects over a multiple year period.

## <a href="/assets/lda-model-example.pdf" class="image fit"><img src="assets/lda-model-example.pdf" alt="Project Overview Presentation (PDF)"></a>

Import packages

```Python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
# pip install gensim (run this in the console if you don't have gensim installed)
import gensim
import time

from gensim import corpora, models, similarities
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import WordNetLemmatizer, SnowballStemmer
from nltk.stem.porter import *
from sklearn.metrics import adjusted_rand_score
```

Define functions necessary for word Processing
```Python
def lemmatize_stemming(text):
    return (WordNetLemmatizer().lemmatize(text, pos='v'))
def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:
            result.append(lemmatize_stemming(token))
    return result
```

The rest...
